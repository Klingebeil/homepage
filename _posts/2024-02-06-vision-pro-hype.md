---
layout: post
language: en
title: "The Vision Pro and the lack of hype"
subtitle: "A Theory"
date: 2024-02-06
teaser-img: 2024-02-06-teaser.png
---

New technologies are often accompanied by [differing amounts of hype](https://johannesklingebiel.de/2022/01/12/hype-as-a-scale.html) and wild speculations about their possible impact. This hype is in many ways notably absent from *Apple’s* new *Vision Pro*, though not for a lack of trying by some people. The main reason, in my opinion, is that the two main rhetorical tactics of amazement and fear simply don’t work for this new gadget.

Hype needs a certain amount of *permissive uncertainty*[^1] to grow. This means it needs an environment in which almost every claim about the effects of the new technology will be understood as somewhat believable. In effect, this is how we make sense of the world, the more uncertain an environment, the more open are we to listen to a greater number of theories about it.

AI is a perfect example in many ways because the term is in itself rather blurry and hard to define and at the same time closely connected with a huge range of dystopian science fiction scenarios. So new developments will always bring with them a high amount of uncertainty for businesses and the public at large. There’s enough reasonable doubt present in the discourse to make claims about the coming disruption(!) and artificial general intelligence(!!) believable, especially when such claims are made by people identified by the public as experts.

Which, importantly, doesn’t mean that these claims are correct or wrong, just that this is the exact media environment in which even the most hyperbolic and out-there claims suddenly seem believable.

Notably a lot of tech commentators are employing two rhetoric strategies to not only fill this uncertainty but also to fuel it. Be that in social networks or on platforms such as *YouTube* but also on conference stages and in the media.

- **Be wowed!** — the technology is an almost magical power, right at your fingertips. Great examples are here the many AI showcases, esp. video and image generation, which tend to be presented as ridiculously advanced, even better than human artists.[^2]
- **Be afraid!** — the technology is a clear and present danger in the near future. Again a good example is here almost everything about the current AI discourse.

Both these tactics are explicitly emotional and tinged with an almost religious fervour. This kind of rhetoric is also focused on the reader who is urged to imagine himself either wielding the power of the technology or how he/she should fear for his job/business/way of life. They’re also often accompanied by what L.M. Sacasas called the "[Borg complex](https://thefrailestthing.com/2013/03/01/borg-complex-a-primer/)": the assertion that resistance against this new technology is not only futile but also either naive or malicious.

## The Vision Pro’s lack of hype

Interestingly these tactics ("be wowed!" & "be afraid!") fail with *Apple*’s new Vision Pro for several reasons:

1. **The device is too mundane** —When looking at the showcases people upload to social media there’s no magic there. On the contrary, most people are instead selling it as the "you can work everywhere"-device. You can have even more screens! You can watch [Mr. Beast while waiting for the subway](https://youtu.be/UvkgmyfMPks?si=ZSXOglbZi4YCnpAv&t=297)! It comes with Excel and Powerpoint! That’s not inspiring, that’s just a laptop strapped to your face.
2. **The device is too familiar** — Besides the so-far underwhelming use-cases, the device (as in a VR/AR goggle) is already familiar. Similar gadgets have been on the market for years. The story was different when the *Magic Leap* and the *Holo Lens* first hit the market around 2015. They were the first of their kind, promising a completely new dimension. Promise that quickly tethered into nothing. 

There’s just not enough room for uncertainty to make speculation seem believable right now, which is why we have seen the same story pop up again and again about this device:

> This is a first generation. The first iPhone was also not that impressive. Just wait for the second and third generation. This is *the future*!

Again, it’s impossible from the present to ascertain if these claims are true or wrong. But what is possible to dissect is the basic argument here: because this has happened, it will happen again, which is why I can now speculate about *the future*. It is an attempt to open up the space for hyperbolic claims, to induce *permissive uncertainty* in the discourse.

This is why I was positively surprised when *The Verge* closed their [excellent product review](https://youtu.be/hdwaWxY11jQ?si=Hy-8MTowTGIaZ_fE&t=1605) by stating how they’re only reviewing what’s in the box, not what the device might imply for the future. Which is not only good journalism but also simply a good way of analyzing new technologies: taking a good and long look inside the (black) box.

[^1]: André Spicer (2020). ‘Playing the Bullshit Game — How Empty and Misleading Communication Takes over Organizations’. Organization Theory, Volume I: I–26
[^2]: Emily Bender wrote a great and fitting essay on AI worth linking here: [Resist the Urge to be Impressed](https://medium.com/@emilymenonbender/on-nyt-magazine-on-ai-resist-the-urge-to-be-impressed-3d92fd9a0edd)